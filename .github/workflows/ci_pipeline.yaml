name: Backend Architecture CI

# Trigger the tests on push to main, or whenever a PR is opened against main
on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

jobs:
  test-and-coverage:
    runs-on: ubuntu-latest
    
    # 1. Spin up the PostgreSQL Service Container
    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
          POSTGRES_DB: pipeline_db
        # Set health checks to wait until postgres has started
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      # 2. Check out the repository code
      - name: Checkout Repository
        uses: actions/checkout@v4

      # 3. Initialize the Database Schema & Roles
      # GitHub Actions services don't auto-mount local folders like docker-compose does, 
      # so we pipe our SQL scripts into the running container directly.
      - name: Initialize Database
        env:
          PGPASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
        run: |
          # Wait a few seconds to ensure DB is fully accepting connections
          sleep 3 
          psql -h localhost -U postgres -d pipeline_db -f db-init/01_schema.sql
          psql -h localhost -U postgres -d pipeline_db -f db-init/02_security.sql
          psql -h localhost -U postgres -d pipeline_db -f db-init/03_triggers.sql

      # 4. Set up Python
      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"
          cache: 'pip' # Automatically caches requirements to speed up future runs

      # 5. Install Dependencies
      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov httpx

      # 6. Run the Test Suite
      - name: Execute Pytest
        env:
          # Inject the highest-privileged role credentials so conftest.py can set up/tear down
          DB_HOST: localhost
          DB_PORT: 5432
          DB_NAME: pipeline_db
          DB_USER: etl_worker
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          # Inject a dummy encryption key for the security/ETL tests
          ENCRYPTION_KEY: ${{ secrets.ENCRYPTION_KEY }}
        run: |
          pytest tests/ \
            --cov=api \
            --cov=etl \
            --cov=src/ont-clinical-pipeline/bin \
            --cov-report=xml \
            --cov-report=term-missing

      # 7. (Optional) Upload Coverage Report
      # Useful if you want to enforce a rule like "PRs must not drop code coverage below 85%"
      - name: Upload coverage reports to Codecov
        uses: codecov/codecov-action@v3
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}